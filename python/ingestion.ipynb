{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure you are in conda environment w/ requirements.txt installed\n",
    "# From root of repo, run: \n",
    "# conda env create -f environment.yml\n",
    "# conda activate semantic_retrieval\n",
    "# Then when selecting kernel for this notebook, pick the conda semantic_retrieval kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obtaining file:///Users/suyogsonwalkar/Projects/semantic-retrieval/python\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Checking if build backend supports build_editable ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build editable ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing editable metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hBuilding wheels for collected packages: semantic-retrieval\n",
      "  Building editable for semantic-retrieval (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for semantic-retrieval: filename=semantic_retrieval-0.1.0-0.editable-py3-none-any.whl size=1704 sha256=01e0d701c2e42807dda4b44266f38e67d28477a94b2a77446bc9acc508169b7b\n",
      "  Stored in directory: /private/var/folders/6m/pqj9tppx6vdg693y_4vlbs2r0000gn/T/pip-ephem-wheel-cache-j9tmqc25/wheels/67/f8/8a/49b91a1167a230dc2c74ea3f6c474e28026431d337e3e4c4a2\n",
      "Successfully built semantic-retrieval\n",
      "Installing collected packages: semantic-retrieval\n",
      "  Attempting uninstall: semantic-retrieval\n",
      "    Found existing installation: semantic-retrieval 0.1.0\n",
      "    Uninstalling semantic-retrieval-0.1.0:\n",
      "      Successfully uninstalled semantic-retrieval-0.1.0\n",
      "Successfully installed semantic-retrieval-0.1.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -e ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to have .env envrionment file (I put mine in root of project for this notebook)\n",
    "# It should have OPENAI_API_KEY, PINECONE_INDEX_NAME, PINECONE_ENVIRONMENT, PINECONE_API_KEY in it\n",
    "# Otherwise will error out on creating embeddings & uploading to pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/envs/semantic_retrieval/lib/python3.11/site-packages/pinecone/index.py:4: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from semantic_retrieval.document.metadata.in_memory_document_metadata_db import (\n",
    "    InMemoryDocumentMetadataDB,\n",
    ")\n",
    "from semantic_retrieval.data_store.vector_dbs.pinecone_vector_db import PineconeVectorDB, PineconeVectorDBConfig\n",
    "from semantic_retrieval.transformation.embeddings.openai_embeddings import OpenAIEmbeddings, OpenAIEmbeddingsConfig\n",
    "from semantic_retrieval.ingestion.data_sources.fs.file_system import FileSystem\n",
    "from semantic_retrieval.document_parsers.multi_document_parser import (\n",
    "    MultiDocumentParser,\n",
    "    ParserConfig,\n",
    ")\n",
    "from semantic_retrieval.transformation.document.text.separator_text_chunker import (\n",
    "    SeparatorTextChunker,\n",
    "    SeparatorTextChunkerParams,\n",
    ")\n",
    "from semantic_retrieval.transformation.document.text.text_chunk_transformer import (\n",
    "    TextChunkConfig,\n",
    ")\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_db = InMemoryDocumentMetadataDB()\n",
    "\n",
    "async def test_create_index():\n",
    "    load_dotenv()\n",
    "\n",
    "    # other_example_dir = \"examples/example_data/financial_report/portfolios\"\n",
    "    example_dir = \"../examples/example_data/ingestion/DonQuixote.txt\"\n",
    "    cwd = os.path.normpath(os.getcwd())\n",
    "    full_path = os.path.join(cwd, example_dir)\n",
    "    file_system = FileSystem(full_path)\n",
    "    raw_documents = file_system.load_documents()\n",
    "\n",
    "    parsed_documents = await MultiDocumentParser().parse_documents(\n",
    "        raw_documents,\n",
    "        parser_config=ParserConfig(\n",
    "            # TODO: Add Access Control Policy Factory & need separate docs / users for this\n",
    "            metadata_db=metadata_db, access_control_policy_factory=None\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    documentTransformer = SeparatorTextChunker(\n",
    "        SeparatorTextChunkerParams(\n",
    "            metadata_db=metadata_db,\n",
    "            text_chunk_config=TextChunkConfig(\n",
    "                chunk_size_limit=500, chunk_overlap=100, size_fn=len\n",
    "            ),\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Transform the parsed documents\n",
    "    transformed_documents = await documentTransformer.transform_documents(\n",
    "        parsed_documents\n",
    "    )\n",
    "\n",
    "    # TODO: Commenting out for now to get tests to pass, will add back in later - want to ship to have notebook ready\n",
    "    # Create the embeddings, use dotenv to get the environment vars & setup properly\n",
    "    await PineconeVectorDB.from_documents(\n",
    "        transformed_documents,\n",
    "        PineconeVectorDBConfig(\n",
    "            index_name=os.getenv(\"PINECONE_INDEX_NAME\", \"\"),\n",
    "            api_key=os.getenv(\"PINECONE_API_KEY\", \"\"),\n",
    "            environment=os.getenv(\"PINECONE_ENVIRONMENT\", \"\"),\n",
    "            namespace=os.getenv(\"PINECONE_NAMESPACE\", \"abc\"),\n",
    "        ),\n",
    "        embeddings=OpenAIEmbeddings(\n",
    "            OpenAIEmbeddingsConfig(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "        ),\n",
    "        metadata_db=metadata_db,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "await test_create_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "semantic_retrieval",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
